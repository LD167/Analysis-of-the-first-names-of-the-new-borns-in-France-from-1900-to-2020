# IMPORT LIBRARIES

import requests
from bs4 import BeautifulSoup
import math

# SCRAP THE WEB SITE "EMMA.CA"

# 1) Retrieve the list of the ethnic origins

url = 'https://emma.ca/prenom'
code_source = BeautifulSoup(requests.get(url).content, 'html.parser')
liste_des_origines = [str.upper(i.text) for i in code_source.find('div', {'class','origin-by-girl'}).find_all('a')]
print('Liste des origines ethniques')
print('')
print(*liste_des_origines)

# 2) Retrieve automatically (with a "While loop") the lists of the first names for all the ethnic origins

# Choice of the current ethnic origin

nombre_origines = len(liste_des_origines)
origine_index = -1
while origine_index < nombre_origines:
	origine_index = origine_index + 1
	origine_libellé = str.lower(liste_des_origines[origine_index])
	origine_libellé_corrigé = str.lower(liste_des_origines[origine_index].replace('è','e').replace('è','e'))

# Title of the current list

	title = 'Prénoms '+str(origine_libellé)
	print('')
	print(title)
	print('')

# Girls first names of the current list

	url_generic = 'https://emma.ca/prenom-fille/'+str(origine_libellé_corrigé)+'?e9c247c9_page='
	if requests.get(url_generic+str(1)).status_code != 200: print('erreur')
	if requests.get(url_generic+str(1)).status_code != 200: continue
	if requests.get(url_generic+str(1)).status_code == 200: print('Filles')
	for web_page in list(range(1,10)): 
		code_source = BeautifulSoup(requests.get(url_generic+str(web_page)).content, 'html.parser')
		liste_des_prénoms_de_filles = [str.upper(i.text) for i in code_source.find('div', {'class','sort-by-baby-names a-to-z w-dyn-list'}).find_all('a') if i.text != 'Précédent' and i.text != 'Suivant' and i.text != 'Ajouter un Prénom']
		print(*liste_des_prénoms_de_filles)
		if [i.text for i in code_source.find('div', {'class','sort-by-baby-names a-to-z w-dyn-list'}).find_all('a') if i.text != 'Précédent' and i.text != 'Suivant'] == ['Ajouter un Prénom']: break 

# Boys first names of the current list
	
	url_generic = 'https://emma.ca/prenom-garcon/'+str(origine_libellé_corrigé)+'?e595c9a7_page='
	if requests.get(url_generic+str(1)).status_code != 200: print('erreur')
	if requests.get(url_generic+str(1)).status_code != 200: continue
	if requests.get(url_generic+str(1)).status_code == 200: print('Garçons')
	for web_page in list(range(1,10)): 
		code_source = BeautifulSoup(requests.get(url_generic+str(web_page)).content, 'html.parser')
		liste_des_prénoms_de_garçons = [str.upper(i.text.replace('Ajouter un Prénom', '')) for i in code_source.find('div', {'class','sort-by-baby-names a-to-z w-dyn-list'}).find_all('a') if i.text != 'Précédent' and i.text != 'Suivant']
		print(*liste_des_prénoms_de_garçons)
		if [i.text for i in code_source.find('div', {'class','sort-by-baby-names a-to-z w-dyn-list'}).find_all('a') if i.text != 'Précédent' and i.text != 'Suivant'] == ['Ajouter un Prénom']: break

# 3) Retrieve manually the lists of the first names for the ethnic origins for which the automatic query has sent an error message



### Calculate the number of ethnic origins labels
nombre_origines = len(liste_des_origines)

### Set the index of the first ethnic origin label to go through
origine_index = 0

### Set the "while loop" condition in order to go through all the indexes
while origine_index < nombre_origines:

# 3) Scrap the list of the girls first names for the ethnic origin label the "while loop" is currently going through

### Correct the wording of the ethnic origin label by lowercasing it and by replacing the strings "é" and "è" by the string "e"
    origine_libellé = str.lower(liste_des_origines[origine_index]).replace('é','e').replace('è','e')

### Set the web page 1 to scrap
    url_generic = 'https://emma.ca/prenom-fille/'+str(origine_libellé)+'?e9c247c9_page='
    url = url_generic+str(1)

### Check the connection to the web page 1
    print(requests.get(url))

### Retrieve the source code of the web page 1
    code_source = BeautifulSoup(requests.get(url).content, 'html.parser')

### Retrieve the title of the web page 1 and correct it by replacing the string " | Emma" by ""
    title = code_source.title.text.replace(' | Emma','')

### Display the corrected title of the web page 1
    print(title)

### Set a "for loop" to go through web page 1 till web page 10 (knowing that less than 10 web pages are dedicated to each ethnic origin label)
    for web_page in list(range(1,10)): 

### Retrieve the source code of each web page one after the other
        code_source = BeautifulSoup(requests.get(url_generic+str(web_page)).content, 'html.parser')

### Retrieve the list of the girls first names from the web page the "for loop" is currently going through
        liste_des_prénoms_de_filles = [i.text.replace('Ajouter un Prénom', 'Fin') for i in code_source.find('div', {'class','sort-by-baby-names a-to-z w-dyn-list'}).find_all('a') if i.text != 'Précédent' and i.text != 'Suivant']  

### Display all the lists of the girls first names from all the web pages (from web page 1 till web page 10)
        print(*liste_des_prénoms_de_filles)

### Set the "for loop" condition in order to stop the loop as soon as the loop reaches the first empty web page without any first name stored (when a web page is empty we find the statement "Ajouter un Prénom" meaning "Add a first name")
        if [i.text for i in code_source.find('div', {'class','sort-by-baby-names a-to-z w-dyn-list'}).find_all('a') if i.text != 'Précédent' and i.text != 'Suivant'] == ['Ajouter un Prénom']: break                    



